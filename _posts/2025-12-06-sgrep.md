---
layout: post
title: Building SGREP
---

Building SGREP
------------------

Recently, there was a great `mrep` tool published by `mxbread` team, helping to address the issue that LLM harnesses such as
claude code, codex, amp, when doing search, spent unnecessary time to retrieve useless tokens. Here's what `mgrep` claim:

```markdown
Why mgrep?
Natural-language search that feels as immediate as grep.
Semantic, multilingual & multimodal (audio, video support coming soon!)
Smooth background indexing via mgrep watch, designed to detect and keep up-to-date everything that matters inside any git repository.
Friendly device-login flow and first-class coding agent integrations.
Built for agents and humans alike, and designed to be a helpful tool, not a restrictive harness: quiet output, thoughtful defaults, and escape hatches everywhere.
Reduces the token usage of your agent by 2x while maintaining superior performance
```
This is quite interesting to me, as myself is learning building out of local coding/review agent (https://github.com/XiaoConstantine/maestro), being in the relevant domain for most of my career, also got amp build crew credits for experience with amp! So why not vibe build a local version myself, not versatile like `mrep` but as good for my use case - Coding related


Getting started
---------------

* So what's the scope?

For my use case, it will be focused on code retrieve for a given repo, for example, when user ask `how should i do prompt optimization` using `maestro` about `dspy-go` repo, maestro should be able to use the tool to find out code, examples.

* How should it be implemented?

I want minimal external dependencies as possible, local first, able to provide accurate and reasonable performant (context efficient) results.

For inference server, I decided to use `llamacpp`

Starting with embeddings
------------------------
Less dependencies, so I m not using any external embeddings store, `sqlite` will be the storage powering vector similarity search (as well as keyword search later in hybrid mode).

The next question is embedding model, a general text embedding model is a good start: `nomic-embed-text-v1.5.Q8_0.gguf`










